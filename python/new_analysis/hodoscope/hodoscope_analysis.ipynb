{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21901544",
   "metadata": {},
   "source": [
    "# Test beam analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bff50c",
   "metadata": {},
   "source": [
    "### Necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17abc9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uproot\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm, moyal\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76961037",
   "metadata": {},
   "source": [
    "### Read the nTuple data into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af4a9a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom order for the keys\n",
    "custom_order = [\n",
    "    'ACT0L', 'ACT0R', 'ACT1L', 'ACT1R', 'ACT3L', 'ACT3R',\n",
    "    'TOF00', 'TOF01', 'TOF02', 'TOF03', 'TOF10', 'TOF11', 'TOF12', 'TOF13',\n",
    "    'TriggerScint',\n",
    "    'PbGlass',\n",
    "    'HD0', 'HD1', 'HD2', 'HD3', 'HD4', 'HD5', 'HD6', 'HD7', 'HD8', 'HD9', 'HD10', 'HD11', 'HD12', 'HD13', 'HD14'\n",
    "]\n",
    "\n",
    "ntuple_dir = \"/Users/jrenner/local/data/beamtest/ntuple_files/\"\n",
    "ntuple_pd_dir = \"/Users/jrenner/temp/hk/beamtest/ntuple_dataframes/\"\n",
    "    \n",
    "def ntuple_to_pd(filename):\n",
    "    \n",
    "    # Open the TTree anaTree and get all keys\n",
    "    events = uproot.open(\"{}:anaTree\".format(filename))\n",
    "    main_keys = events.keys()\n",
    "    \n",
    "    # Construct the analysis dataframe\n",
    "    df = pd.DataFrame()\n",
    "    for key in main_keys:\n",
    "        \n",
    "        # Skip the nChannels key\n",
    "        if(key == 'nChannels'):\n",
    "            continue\n",
    "\n",
    "        arr = events[key].array(library='np').squeeze()\n",
    "\n",
    "        # Convert the array to a DataFrame\n",
    "        df_key = pd.DataFrame(arr)\n",
    "\n",
    "        # Rename the columns to include the key name\n",
    "        df_key.columns = [f\"{key}{i}\" for i in df_key.columns]\n",
    "\n",
    "        # Concatenate the new DataFrame to the existing one\n",
    "        df = pd.concat([df, df_key], axis=1)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def ntuple_to_pd_multipeak(filename):\n",
    "    \n",
    "    # Open the TTree anaTree and get all keys\n",
    "    events = uproot.open(\"{}\".format(filename))\n",
    "    main_keys = events.keys()\n",
    "    \n",
    "    # Construct the analysis dataframes for each detector element.\n",
    "    df_dict = {}\n",
    "    for key in main_keys:\n",
    "        \n",
    "        key_noversion = key.split(';')[0]\n",
    "        \n",
    "        # Skip the EventInfo key\n",
    "        if(key_noversion == 'EventInfo'):\n",
    "            continue\n",
    "        \n",
    "        print(\"Processing dataframe for\",key,\"...\")\n",
    "        \n",
    "        # Get the number of peaks and timestamps\n",
    "        nPeaks        = events[key]['nPeaks'].array()\n",
    "        timeStamp     = events[key]['timeStamp'].array()\n",
    "        triggerTime   = events[key]['triggerTime'].array()\n",
    "        Pedestal      = events[key]['Pedestal'].array()\n",
    "        PedestalSigma = events[key]['PedestalSigma'].array()\n",
    "        PeakVoltage   = events[key]['PeakVoltage'].array()\n",
    "        PeakTime      = events[key]['PeakTime'].array()\n",
    "        SignalTime    = events[key]['SignalTime'].array()\n",
    "        IntCharge     = events[key]['IntCharge'].array()\n",
    "        \n",
    "        # Iterate through the array elements and save information for each peak.\n",
    "        l_evt, l_ipk, l_nPeaks, l_timeStamp, l_triggerTime = [], [], [], [], []\n",
    "        l_Pedestal, l_PedestalSigma = [], []\n",
    "        l_PeakVoltage, l_PeakTime, l_SignalTime, l_IntCharge = [], [], [], []\n",
    "        for evt, (npk, tstamp, ttime, pedestal, spedestal, pkv, pkt, sigt, chg) in enumerate(zip(nPeaks,timeStamp,triggerTime,Pedestal,PedestalSigma,PeakVoltage,PeakTime,SignalTime,IntCharge)):\n",
    "            \n",
    "            # Update the lists for each peak.\n",
    "            if(npk == 0):\n",
    "                l_evt.append(evt)\n",
    "                l_ipk.append(-1)\n",
    "                l_nPeaks.append(npk)\n",
    "                l_timeStamp.append(tstamp)\n",
    "                l_triggerTime.append(ttime)\n",
    "                l_Pedestal.append(pedestal)\n",
    "                l_PedestalSigma.append(spedestal)\n",
    "                l_PeakVoltage.append(-1)\n",
    "                l_PeakTime.append(-1)\n",
    "                l_SignalTime.append(-1)\n",
    "                l_IntCharge.append(-1)\n",
    "            else:\n",
    "                for ipk in range(npk):\n",
    "                    l_evt.append(evt)\n",
    "                    l_ipk.append(ipk)\n",
    "                    l_nPeaks.append(npk)\n",
    "                    l_timeStamp.append(tstamp)\n",
    "                    l_triggerTime.append(ttime)\n",
    "                    l_Pedestal.append(pedestal)\n",
    "                    l_PedestalSigma.append(spedestal)\n",
    "                    l_PeakVoltage.append(pkv[ipk])\n",
    "                    l_PeakTime.append(pkt[ipk])\n",
    "                    l_SignalTime.append(sigt[ipk])\n",
    "                    l_IntCharge.append(chg[ipk])\n",
    "        \n",
    "        # Create a new dataframe.\n",
    "        df = pd.DataFrame({'event':  l_evt,\n",
    "                           'iPeak': l_ipk,\n",
    "                           'nPeaks': l_nPeaks,\n",
    "                           'timeStamp': l_timeStamp,\n",
    "                           'triggerTime': l_triggerTime,\n",
    "                           'Pedestal': l_Pedestal,\n",
    "                           'PedestalSigma': l_PedestalSigma,\n",
    "                           'PeakVoltage': l_PeakVoltage,\n",
    "                           'PeakTime': l_PeakTime,\n",
    "                           'SignalTime': l_SignalTime,\n",
    "                           'IntCharge': l_IntCharge\n",
    "                          })\n",
    "\n",
    "        # Set this as the dataframe or concatenate it to the one that is already there.\n",
    "        if(key_noversion in df_dict):\n",
    "            last_evt = df_dict[key_noversion]['event'].values[-1]+1\n",
    "            df['event'] = df['event'] + last_evt\n",
    "            print(\"Concatenating to\",key_noversion,\"starting with event number\",last_evt)\n",
    "            df_dict[key_noversion] = pd.concat([df_dict[key_noversion], df], ignore_index=True)\n",
    "        else:\n",
    "            df_dict[key_noversion] = df\n",
    "            \n",
    "    # Add EventInfo information.\n",
    "    df = pd.DataFrame( {'RunNumber':   events['EventInfo']['RunNumber'].array(library='np'),\n",
    "                        'EventNumber': events['EventInfo']['EventNumber'].array(library='np'),\n",
    "                        'SpillNumber': events['EventInfo']['SpillNumber'].array(library='np')})\n",
    "    df_dict['EventInfo'] = df\n",
    "        \n",
    "    return df_dict\n",
    "\n",
    "def plot_histograms_for_each_signal(df_dict, base_dir=\".\", rnum = 0, quantity='nPeaks', select_nonzero_peaks=False, logscale=False, nbins=60):\n",
    "    \n",
    "    out_dir = f\"{base_dir}/{rnum}\"\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "        \n",
    "    print(\"Plotting all histograms for\",quantity,\"for all signals in run\",rnum)\n",
    "\n",
    "    # Create a grid of 8 rows x 4 columns\n",
    "    fig, axes = plt.subplots(8, 4, figsize=(16, 24))\n",
    "    flat_axes = axes.ravel()\n",
    "    \n",
    "    fig.suptitle(f'Run {rnum}', fontsize=24, y=1.02)\n",
    "\n",
    "    # Iterate based on the custom order\n",
    "    for key, ax in zip(custom_order, flat_axes):\n",
    "        df = df_dict[key]\n",
    "        \n",
    "        # Select only non-zero peaks if specified.\n",
    "        if(select_nonzero_peaks):\n",
    "            df_select = df[df['nPeaks'] > 0]\n",
    "        else:\n",
    "            df_select = df\n",
    "            \n",
    "        # Place a cut if we're looking at an HD element and plotting PeakVoltage or IntCharge.\n",
    "        if(key[0:2] == 'HD' and (quantity == 'IntCharge' or quantity == 'PeakVoltage')):\n",
    "            df_select = df[df[quantity] > 0.02]\n",
    "\n",
    "        # Plot histogram for the current signal on its corresponding axis\n",
    "        n, bins, patches = ax.hist(df_select[quantity], bins=nbins, edgecolor='black', alpha=0.7, label=key)  # capture output to use in legend\n",
    "        #ax.set_title(key)\n",
    "        ax.set_xlabel(quantity)\n",
    "        ax.set_ylabel('Counts/bin')\n",
    "        ax.legend()  # Add legend\n",
    "        \n",
    "        if(logscale):\n",
    "            ax.set_yscale('log')\n",
    "\n",
    "    # Adjust the layout so the plots do not overlap\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    plt.savefig(f\"{out_dir}/{quantity}.pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def read_dataframes_from_csv(directory):\n",
    "    file_names = os.listdir(directory)\n",
    "    dfs = {}\n",
    "    for file in file_names:\n",
    "        if file.endswith('.csv'):\n",
    "            key = file.split('.csv')[0]\n",
    "            dfs[key] = pd.read_csv(os.path.join(directory, file))\n",
    "    return dfs\n",
    "\n",
    "def compute_statistics(df):\n",
    "    \n",
    "    # Compute average statistics\n",
    "    avg_nPeaks = df['nPeaks'].mean()\n",
    "    avg_Pedestal = df['Pedestal'].mean()\n",
    "    avg_PedestalSigma = df['PedestalSigma'].mean()\n",
    "    \n",
    "    # For histograms, bin the data and find the bin with the most counts\n",
    "    def get_hist_peak(data, bins=100):\n",
    "        hist, bin_edges = np.histogram(data, bins=bins)\n",
    "        peak_bin = np.argmax(hist)\n",
    "        peak_value = (bin_edges[peak_bin] + bin_edges[peak_bin + 1]) / 2\n",
    "        return peak_value\n",
    "\n",
    "    peak_PeakVoltage = get_hist_peak(df[df['PeakVoltage'] > 0.2]['PeakVoltage'])\n",
    "    peak_PeakTime = get_hist_peak(df[df['PeakTime'] > 10]['PeakTime'])\n",
    "    peak_SignalTime = get_hist_peak(df[df['SignalTime'] > 0.2]['SignalTime'])\n",
    "    peak_IntCharge = get_hist_peak(df[df['IntCharge'] > 0.025]['IntCharge'])\n",
    "    \n",
    "    stats = {\n",
    "        'avg_nPeaks': avg_nPeaks,\n",
    "        'avg_Pedestal': avg_Pedestal,\n",
    "        'avg_PedestalSigma': avg_PedestalSigma,\n",
    "        'peak_PeakVoltage': peak_PeakVoltage,\n",
    "        'peak_PeakTime': peak_PeakTime,\n",
    "        'peak_SignalTime': peak_SignalTime,\n",
    "        'peak_IntCharge': peak_IntCharge\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "def plot_statistics_vs_run(statistics_data, statistic_keys, signal_set, base_dir, signal_set_name):\n",
    "    \n",
    "    out_dir = f\"{base_dir}/summary\"\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "        \n",
    "    n_statistics = len(statistic_keys)\n",
    "    \n",
    "    # Define number of rows and columns for the subplots.\n",
    "    n_cols = 1\n",
    "    n_rows = math.ceil(n_statistics / n_cols)\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "    \n",
    "    if n_statistics == 1:\n",
    "        axes = [axes]\n",
    "        \n",
    "    # Generate a palette with as many distinct colors as there are signals.\n",
    "    #palette = sns.color_palette(\"husl\", len(signal_set))\n",
    "    \n",
    "    for idx, statistic_key in enumerate(statistic_keys):\n",
    "        ax = axes[idx]\n",
    "        #ax = axes[idx//n_cols, idx%n_cols] if n_rows > 1 else axes[idx]\n",
    "        \n",
    "        # Set the color cycle for this axis\n",
    "        #ax.set_prop_cycle(color=palette)\n",
    "        \n",
    "        for idkey,key in enumerate(signal_set):\n",
    "            marker = 's'\n",
    "            if(idkey > 9): marker = 'o'\n",
    "            runs = list(statistics_data.keys())\n",
    "            values = [statistics_data[run][key][statistic_key] for run in runs]\n",
    "            ax.plot(runs, values, marker=marker, label=key)\n",
    "        \n",
    "        #ax.set_title(f\"{statistic_key} vs. Run Number\")\n",
    "        ax.set_xlabel(\"Run Number\",fontsize=14)\n",
    "        ax.set_ylabel(statistic_key,fontsize=14)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    \n",
    "    # Handle case when the number of plots is odd\n",
    "    #if n_statistics % 2 != 0 and n_rows > 1:\n",
    "        #axes[n_rows-1, 1].axis('off')\n",
    "    #    axes[n_rows-1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    plt.savefig(f\"{out_dir}/{signal_set_name}.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15238aa2",
   "metadata": {},
   "source": [
    "### Create dataframes for all runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc275ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = np.arange(630,766)\n",
    "for run in runs:\n",
    "    ntuple_file = \"{}/ntuple_000{}.root\".format(ntuple_dir,run)\n",
    "    output_dir = \"{}/run000{}\".format(ntuple_pd_dir,run)\n",
    "    \n",
    "    # Make sure the file exists\n",
    "    if(not os.path.isfile(ntuple_file)):\n",
    "        continue\n",
    "    \n",
    "    print(\"Creating dataframes for run\",run,\"...\")\n",
    "    \n",
    "    # Create the dataframe dictionary\n",
    "    df_dict = ntuple_to_pd_multipeak(ntuple_file)\n",
    "\n",
    "    # Save all the dataframes for this run\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for key, df in df_dict.items():\n",
    "        filepath = os.path.join(output_dir, f\"{key}.csv\")\n",
    "        df.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a5c36",
   "metadata": {},
   "source": [
    "### Plot all quantities for each signal for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e97a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing statistics for run 730\n",
      "Plotting all histograms for nPeaks for all signals in run 000730\n",
      "Plotting all histograms for timeStamp for all signals in run 000730\n",
      "Plotting all histograms for triggerTime for all signals in run 000730\n",
      "Plotting all histograms for Pedestal for all signals in run 000730\n",
      "Plotting all histograms for PedestalSigma for all signals in run 000730\n",
      "Plotting all histograms for PeakVoltage for all signals in run 000730\n",
      "Plotting all histograms for PeakTime for all signals in run 000730\n",
      "Plotting all histograms for SignalTime for all signals in run 000730\n",
      "Plotting all histograms for IntCharge for all signals in run 000730\n",
      "Computing statistics for run 731\n",
      "Plotting all histograms for nPeaks for all signals in run 000731\n",
      "Plotting all histograms for timeStamp for all signals in run 000731\n",
      "Plotting all histograms for triggerTime for all signals in run 000731\n",
      "Plotting all histograms for Pedestal for all signals in run 000731\n",
      "Plotting all histograms for PedestalSigma for all signals in run 000731\n"
     ]
    }
   ],
   "source": [
    "runs = np.arange(730,766)\n",
    "for run in runs:\n",
    "    rnum = f\"000{run}\"\n",
    "    run_dir = \"{}/run{}\".format(ntuple_pd_dir, rnum)\n",
    "    \n",
    "    # Make sure the run exists\n",
    "    if(run < 720 or not os.path.isdir(run_dir)):\n",
    "        continue\n",
    "        \n",
    "    print(\"Computing statistics for run\",run)\n",
    "\n",
    "    # Read in all dataframes for this run\n",
    "    df_dict = read_dataframes_from_csv(run_dir)\n",
    "    \n",
    "    plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='nPeaks', select_nonzero_peaks=False, logscale=False, nbins=20)\n",
    "    plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='timeStamp', select_nonzero_peaks=False, logscale=False, nbins=40)\n",
    "    plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='triggerTime', select_nonzero_peaks=False, logscale=False, nbins=40)\n",
    "    plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='Pedestal', select_nonzero_peaks=False, logscale=True, nbins=60)\n",
    "    plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='PedestalSigma', select_nonzero_peaks=False, logscale=True, nbins=60)\n",
    "    plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='PeakVoltage', select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "    plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='PeakTime', select_nonzero_peaks=True, logscale=False, nbins=40)\n",
    "    plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='SignalTime', select_nonzero_peaks=True, logscale=False, nbins=60)\n",
    "    plot_histograms_for_each_signal(df_dict, base_dir='plt', rnum=rnum, quantity='IntCharge', select_nonzero_peaks=True, logscale=False, nbins=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb15d4c6",
   "metadata": {},
   "source": [
    "## Compute and plot statistics for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc0b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_data = {}\n",
    "\n",
    "runs = np.arange(630,766)\n",
    "for run in runs:\n",
    "    run_dir = \"{}/run000{}\".format(ntuple_pd_dir, run)\n",
    "    \n",
    "    # Make sure the run exists\n",
    "    if(run < 720 or not os.path.isdir(run_dir)):\n",
    "        continue\n",
    "        \n",
    "    print(\"Computing statistics for run\",run)\n",
    "\n",
    "    # Read in all dataframes for this run\n",
    "    df_dict = read_dataframes_from_csv(run_dir)\n",
    "    \n",
    "    # Compute statistics for this run and save them\n",
    "    statistics_data[run] = {}\n",
    "    for key in custom_order:\n",
    "        statistics_data[run][key] = compute_statistics(df_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456d2455",
   "metadata": {},
   "source": [
    "#### Plot summary statistics from each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce525e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_keys = ['avg_nPeaks', 'avg_Pedestal', 'avg_PedestalSigma', 'peak_PeakVoltage', 'peak_PeakTime', 'peak_SignalTime', 'peak_IntCharge']\n",
    "act_set = ['ACT0L', 'ACT0R', 'ACT1L', 'ACT1R', 'ACT3L', 'ACT3R', 'PbGlass']\n",
    "tof_set = ['TOF00', 'TOF01', 'TOF02', 'TOF03', 'TOF10', 'TOF11', 'TOF12', 'TOF13', 'TriggerScint']\n",
    "hd_set  = ['HD0', 'HD1', 'HD2', 'HD3', 'HD4', 'HD5', 'HD6', 'HD7', 'HD8', 'HD9', 'HD10', 'HD11', 'HD12', 'HD13', 'HD14']\n",
    "\n",
    "plot_statistics_vs_run(statistics_data, statistics_keys, act_set, base_dir='plt', signal_set_name='ACT')\n",
    "plot_statistics_vs_run(statistics_data, statistics_keys, tof_set, base_dir='plt', signal_set_name='TOF')\n",
    "plot_statistics_vs_run(statistics_data, statistics_keys, hd_set, base_dir='plt', signal_set_name='HD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00133d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25e9096a",
   "metadata": {},
   "source": [
    "# Gamma peak analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9521243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_duplicates(arr):\n",
    "    u, c = np.unique(arr, return_counts=True)\n",
    "    return np.sum(c[c > 1])\n",
    "\n",
    "def filter_range(name,df,key,rng,drop=False):\n",
    "    \n",
    "    # Perform the filter.\n",
    "    df_filtered = df[df[key].between(*rng)]\n",
    "    nduplicates = get_num_duplicates(df_filtered['event'].values)\n",
    "    print(f\"{name} filter passed\",len(df_filtered),\"of\",len(df),\"with\",nduplicates,\"duplicates\")\n",
    "    \n",
    "    # Handle duplicates.\n",
    "    if(nduplicates > 0):\n",
    "        \n",
    "        # Drop all events that appear more than once if selected.\n",
    "        if(drop):\n",
    "            df_filtered = df_filtered[~df_filtered['event'].duplicated(keep=False)]\n",
    "        # Otherwise choose the one with the maximum integrated charge.\n",
    "        else:\n",
    "            idx = df_filtered.groupby('event')['IntCharge'].idxmax()\n",
    "            df_filtered = df_filtered.loc[idx]\n",
    "        \n",
    "    print(\"--> returning\",len(df_filtered),\"events\")\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fd526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in all dataframes from a given run\n",
    "df_dict = read_dataframes_from_csv(\"/Users/jrenner/temp/hk/beamtest/ntuple_dataframes/run000734\")\n",
    "df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7398e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict['ACT0L'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0a8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 'PbGlass' Peaks Based on Timing\n",
    "pb_timing_range = (40, 90)\n",
    "pb_filtered = filter_range(\"PbGlass\",df_dict['PbGlass'],'PeakTime',pb_timing_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63dfcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter TOF elements\n",
    "tof0_timing_range = (45, 85)\n",
    "tof0_charge_range = (0.3, 1.0)\n",
    "tof1_timing_range = (60, 100)\n",
    "tof1_charge_range = (0.3, 1.0)\n",
    "t2_timing_range = (160, 180)\n",
    "t2_charge_range = (0.01, 0.0225)\n",
    "\n",
    "# TOF0\n",
    "tof00_filtered = filter_range(\"TOF00\",df_dict['TOF00'],'PeakTime',tof0_timing_range)\n",
    "tof01_filtered = filter_range(\"TOF01\",df_dict['TOF01'],'PeakTime',tof0_timing_range)\n",
    "tof02_filtered = filter_range(\"TOF02\",df_dict['TOF02'],'PeakTime',tof0_timing_range)\n",
    "tof03_filtered = filter_range(\"TOF03\",df_dict['TOF03'],'PeakTime',tof0_timing_range)\n",
    "\n",
    "combined_00_01 = tof00_filtered.merge(tof01_filtered, on='event', suffixes=('_00', '_01'))\n",
    "combined_00_01_02 = combined_00_01.merge(tof02_filtered, on='event')\n",
    "combined_00_01_02 = combined_00_01_02.rename(columns={'IntCharge': 'IntCharge_02'})\n",
    "tof0_combined = combined_00_01_02.merge(tof03_filtered, on='event')\n",
    "tof0_combined = tof0_combined.rename(columns={'IntCharge': 'IntCharge_03'})\n",
    "tof0_combined['combined_charge'] = (tof0_combined['IntCharge_00'] \n",
    "                                  + tof0_combined['IntCharge_01']\n",
    "                                  + tof0_combined['IntCharge_02']\n",
    "                                  + tof0_combined['IntCharge_03'])\n",
    "\n",
    "tof0_valid = filter_range(\"TOF0_combined\",tof0_combined,'combined_charge',tof0_charge_range)\n",
    "tof0_valid.loc[:,'hit_TOF0'] = 1\n",
    "print()\n",
    "\n",
    "# TOF1\n",
    "tof10_filtered = filter_range(\"TOF10\",df_dict['TOF10'],'PeakTime',tof1_timing_range)\n",
    "tof11_filtered = filter_range(\"TOF11\",df_dict['TOF11'],'PeakTime',tof1_timing_range)\n",
    "tof12_filtered = filter_range(\"TOF12\",df_dict['TOF12'],'PeakTime',tof1_timing_range)\n",
    "tof13_filtered = filter_range(\"TOF13\",df_dict['TOF13'],'PeakTime',tof1_timing_range)\n",
    "\n",
    "combined_10_11 = tof10_filtered.merge(tof11_filtered, on='event', suffixes=('_10', '_11'))\n",
    "combined_10_11_12 = combined_10_11.merge(tof12_filtered, on='event')\n",
    "combined_10_11_12 = combined_10_11_12.rename(columns={'IntCharge': 'IntCharge_12'})\n",
    "tof1_combined = combined_10_11_12.merge(tof13_filtered, on='event')\n",
    "tof1_combined = tof1_combined.rename(columns={'IntCharge': 'IntCharge_13'})\n",
    "tof1_combined['combined_charge'] = (tof1_combined['IntCharge_10'] \n",
    "                                  + tof1_combined['IntCharge_11']\n",
    "                                  + tof1_combined['IntCharge_12']\n",
    "                                  + tof1_combined['IntCharge_13'])\n",
    "\n",
    "tof1_valid = filter_range(\"TOF1_combined\",tof1_combined,'combined_charge',tof1_charge_range)\n",
    "tof1_valid.loc[:,'hit_TOF1'] = 1\n",
    "print()\n",
    "\n",
    "# T2\n",
    "t2_filtered = filter_range(\"T2\",df_dict['TriggerScint'],'PeakTime',t2_timing_range)\n",
    "t2_valid = filter_range(\"T2\",t2_filtered,'IntCharge',t2_charge_range)\n",
    "t2_valid.loc[:,'hit_T2'] = 1\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0067caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the ACT elements\n",
    "act0_timing_range = (130, 175)\n",
    "act0_charge_range = (0.1, 1.0)\n",
    "act1_timing_range = (130, 175)\n",
    "act1_charge_range = (0.02, 0.2)\n",
    "act3_timing_range = (150, 190)\n",
    "\n",
    "# ACT0\n",
    "act0l_filtered = filter_range(\"ACT0L\",df_dict['ACT0L'],'PeakTime',act0_timing_range)\n",
    "act0r_filtered = filter_range(\"ACT0R\",df_dict['ACT0R'],'PeakTime',act0_timing_range)\n",
    "\n",
    "act0_combined = act0l_filtered.merge(act0r_filtered, on='event', suffixes=('_L', '_R'))\n",
    "act0_combined['combined_charge'] = act0_combined['IntCharge_L'] + act0_combined['IntCharge_R']\n",
    "\n",
    "act0_valid = filter_range(\"ACT0_combined\",act0_combined,'combined_charge',act0_charge_range)\n",
    "act0_valid.loc[:,'hit_ACT0'] = 1\n",
    "\n",
    "# ACT1\n",
    "act1l_filtered = filter_range(\"ACT1L\",df_dict['ACT1L'],'PeakTime',act1_timing_range)\n",
    "act1r_filtered = filter_range(\"ACT1R\",df_dict['ACT1R'],'PeakTime',act1_timing_range)\n",
    "\n",
    "act1_combined = act1l_filtered.merge(act1r_filtered, on='event', suffixes=('_L', '_R'))\n",
    "act1_combined['combined_charge'] = act1_combined['IntCharge_L'] + act1_combined['IntCharge_R']\n",
    "\n",
    "act1_valid = filter_range(\"ACT1_combined\",act1_combined,'combined_charge',act1_charge_range)\n",
    "act1_valid.loc[:,'hit_ACT1'] = 1\n",
    "\n",
    "# ACT3\n",
    "act3l_filtered = df_dict['ACT3L'][df_dict['ACT3L']['nPeaks'] == 0]\n",
    "act3r_filtered = df_dict['ACT3R'][df_dict['ACT3R']['nPeaks'] == 0]\n",
    "\n",
    "act3_combined = act3l_filtered.merge(act3r_filtered, on='event', suffixes=('_L', '_R'))\n",
    "act3_valid = act3_combined.copy()\n",
    "act3_valid.loc[:,'nohit_ACT3'] = 1\n",
    "print(\"ACT3 total number of valid events:\",len(act3_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter hodoscope elements\n",
    "hd_dfs = {}\n",
    "hd_timing_ranges = {\n",
    "    'HD0': (35, 75),\n",
    "    'HD1': (35, 75),\n",
    "    'HD2': (35, 75),\n",
    "    'HD3': (35, 75),\n",
    "    'HD4': (35, 75),\n",
    "    'HD5': (35, 75),\n",
    "    'HD6': (35, 75),\n",
    "    'HD7': (35, 75),\n",
    "    'HD8': (80, 120),\n",
    "    'HD9': (80, 120),\n",
    "    'HD10': (80, 120),\n",
    "    'HD11': (80, 120),\n",
    "    'HD12': (80, 120),\n",
    "    'HD13': (80, 120),\n",
    "    'HD14': (80, 120)\n",
    "}\n",
    "hd_charge_threshold = 0.025  # Replace with your value\n",
    "\n",
    "# Create the filtered dataframes (containing peaks over the threshold at the correct time).\n",
    "for i in range(15):  # 0 to 14 inclusive\n",
    "    hd_key = f'HD{i}'\n",
    "    hit_col_name = f'hit_{hd_key}'\n",
    "    hd_range = hd_timing_ranges[hd_key]\n",
    "    \n",
    "    # Filtering\n",
    "    filtered = df_dict[hd_key][(df_dict[hd_key]['PeakTime'].between(*hd_range)) & \n",
    "                               (df_dict[hd_key]['IntCharge'] > hd_charge_threshold)]\n",
    "    print(f\"HD{i}: {len(filtered)} of {len(df_dict[hd_key])} events after filter\")\n",
    "    \n",
    "    # Assign a binary value indicating a hit\n",
    "    if not filtered.empty:\n",
    "        filtered.loc[:,hit_col_name] = 1\n",
    "    else:\n",
    "        filtered.loc[:,hit_col_name] = 0\n",
    "\n",
    "    hd_dfs[hd_key] = filtered\n",
    "\n",
    "# Merge all HD dataframes\n",
    "combined_hd_df = hd_dfs['HD0'][['event', 'hit_HD0']]\n",
    "for i in range(1, 15):\n",
    "    hd_key = f'HD{i}'\n",
    "    hit_col_name = f'hit_{hd_key}'\n",
    "    \n",
    "    combined_hd_df = combined_hd_df.merge(\n",
    "        hd_dfs[hd_key][['event', hit_col_name]],\n",
    "        on='event',\n",
    "        how='outer'\n",
    "    ).fillna(0)\n",
    "\n",
    "# Calculate total hits per event\n",
    "combined_hd_df['total_hits'] = combined_hd_df.filter(like='hit_').sum(axis=1)\n",
    "\n",
    "# Filter events with a hit count of 1\n",
    "hd_valid_events = combined_hd_df[combined_hd_df['total_hits'] == 1]\n",
    "\n",
    "u, c = np.unique(combined_hd_df['event'].values, return_counts=True)\n",
    "print(\"Duplicates in combined HD dataframe:\",np.sum(c[c > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0cc1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all relevant dataframes\n",
    "final_df = pb_filtered.merge(hd_valid_events, on='event', how='inner')\n",
    "final_df = final_df.merge(act0_valid[['event', 'hit_ACT0']], on='event', how='left')\n",
    "final_df = final_df.merge(act1_valid[['event', 'hit_ACT1']], on='event', how='left')\n",
    "final_df = final_df.merge(act3_valid[['event', 'nohit_ACT3']], on='event', how='left')\n",
    "final_df = final_df.merge(tof0_valid[['event', 'hit_TOF0']], on='event', how='left')\n",
    "final_df = final_df.merge(tof1_valid[['event', 'hit_TOF1']], on='event', how='left')\n",
    "final_df = final_df.merge(t2_valid[['event', 'hit_T2']], on='event', how='left')\n",
    "\n",
    "# Fill NaN values in the hit columns with 0\n",
    "final_df[['hit_ACT0', 'hit_ACT1', 'nohit_ACT3', 'hit_TOF0', 'hit_TOF1', 'hit_T2']] = final_df[['hit_ACT0', 'hit_ACT1', 'nohit_ACT3', 'hit_TOF0', 'hit_TOF1', 'hit_T2']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a22c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_all = (final_df.total_hits == 1) & (final_df.hit_ACT0 == 1) & \\\n",
    "           (final_df.hit_ACT1 == 1) & (final_df.nohit_ACT3 == 1) & \\\n",
    "           (final_df.hit_TOF0 == 1) & (final_df.hit_TOF1 == 1) & (final_df.hit_T2 == 1)\n",
    "nbins = 60\n",
    "\n",
    "cuts = cuts_all\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD14\")\n",
    "plt.hist(final_df[(final_df.hit_HD13 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD13\")\n",
    "plt.hist(final_df[(final_df.hit_HD12 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD12\")\n",
    "plt.hist(final_df[(final_df.hit_HD11 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD11\")\n",
    "plt.hist(final_df[(final_df.hit_HD10 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD10\")\n",
    "plt.hist(final_df[(final_df.hit_HD9 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD9\")\n",
    "plt.hist(final_df[(final_df.hit_HD8 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD8\")\n",
    "plt.hist(final_df[(final_df.hit_HD7 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD7\")\n",
    "plt.hist(final_df[(final_df.hit_HD6 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD6\")\n",
    "plt.hist(final_df[(final_df.hit_HD5 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD5\")\n",
    "plt.hist(final_df[(final_df.hit_HD4 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD4\")\n",
    "plt.hist(final_df[(final_df.hit_HD3 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD3\")\n",
    "plt.hist(final_df[(final_df.hit_HD2 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD2\")\n",
    "plt.hist(final_df[(final_df.hit_HD1 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD1\")\n",
    "plt.hist(final_df[(final_df.hit_HD0 == 1) & cuts]['IntCharge'],bins=nbins,label=\"HD0\")\n",
    "plt.xlabel(\"Lead glass charge\",fontsize=14)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=14)\n",
    "plt.title(\"RUN 000734, p = + 0.7 GeV/c\",fontsize=20)\n",
    "plt.legend()\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f241172",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_all = (final_df.total_hits == 1) \n",
    "cuts_ACT0 = cuts_all & (final_df.hit_ACT0 == 1)\n",
    "cuts_ACT1 = cuts_ACT0 & (final_df.hit_ACT1 == 1)\n",
    "cuts_ACT3 = cuts_ACT1 & (final_df.nohit_ACT3 == 1)\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_all]['IntCharge'],bins=40,label=\"HD14\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_ACT0]['IntCharge'],bins=40,label=\"HD14+ACT0\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_ACT1]['IntCharge'],bins=40,label=\"HD14+ACT0/1\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_ACT3]['IntCharge'],bins=40,label=\"HD14+ACT0/1/3\")\n",
    "\n",
    "plt.xlabel(\"Lead glass charge\",fontsize=14)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=14)\n",
    "plt.title(\"RUN 000734, p = + 0.7 GeV/c\",fontsize=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134f225",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts_all = (final_df.total_hits == 1) \n",
    "cuts_TOF0 = cuts_all & (final_df.hit_TOF0 == 1)\n",
    "cuts_TOF1 = cuts_TOF0 & (final_df.hit_TOF1 == 1)\n",
    "cuts_T2 = cuts_TOF1 & (final_df.hit_T2 == 1)\n",
    "\n",
    "fig = plt.figure(figsize=(14,7))\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_all]['IntCharge'],bins=40,label=\"HD14\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_TOF0]['IntCharge'],bins=40,label=\"HD14+TOF0\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_TOF1]['IntCharge'],bins=40,label=\"HD14+TOF0/1\")\n",
    "plt.hist(final_df[(final_df.hit_HD14 == 1) & cuts_T2]['IntCharge'],bins=40,label=\"HD14+TOF0/1/2\")\n",
    "\n",
    "plt.xlabel(\"Lead glass charge\",fontsize=14)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=14)\n",
    "plt.title(\"RUN 000734, p = + 0.7 GeV/c\",fontsize=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eedd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(df_dict['ACT3L'][df_dict['ACT3L']['PeakTime'] > 10]['PeakTime'],bins=100)\n",
    "plt.hist(df_dict['ACT1L'][df_dict['ACT1L']['PeakTime'] > 10]['PeakTime'],bins=100)\n",
    "#plt.hist(act0_combined['combined_charge'],bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed3dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(tof1_combined['combined_charge'],bins=100,range=[0,1])\n",
    "#plt.hist(df_dict['TOF00']['PeakTime'],bins=100,range=[35,90])\n",
    "#plt.hist(df_dict['TriggerScint']['IntCharge'],bins=100,range=[0,0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed19cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = uproot.open(\"{}\".format(\"../ntuples/ntuple_000734.root\"))\n",
    "main_keys = events.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db566634",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97682066",
   "metadata": {},
   "source": [
    "## Single-peak analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5735f8d3",
   "metadata": {},
   "source": [
    "### Runs 670 - 677: Trigger T0 and T2 Coincidence with Hodoscope OR Lead Glass - 1% Slit\n",
    "#### Please note that ntuples 672 (700 MeV), 674 (900 MeV), 675 (1 GeV) and 716 (700 MeV) cannot be produced with Nick script. This is something that may need to be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df481e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the ROOT file to a CSV\n",
    "run  = \"000734\"\n",
    "path = \"../ntuples/ntuple_\"\n",
    "df   = ntuple_to_pd(path + \"{}.root\".format(run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4175dd46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14455cf2",
   "metadata": {},
   "source": [
    "## Peak time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c6d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create entries in dataframe for averages in peak times\n",
    "df['PeakTimeACT0'] = (df['PeakTime0'] + df['PeakTime1'])/2\n",
    "df['PeakTimeACT1'] = (df['PeakTime2'] + df['PeakTime3'])/2\n",
    "df['PeakTimeACT3'] = (df['PeakTime4'] + df['PeakTime5'])/2\n",
    "df['PeakVoltageACT3'] = (df['PeakVoltage4'] + df['PeakVoltage5'])/2\n",
    "df['PeakTimeTOF0'] = (df['PeakTime8'] + df['PeakTime9'] + df['PeakTime10'] + df['PeakTime11'])/4\n",
    "df['PeakTimeTOF1'] = (df['PeakTime12'] + df['PeakTime13'] + df['PeakTime14'] + df['PeakTime15'])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5567a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_time = [0,200]\n",
    "nbins_time = 100\n",
    "\n",
    "fig = plt.figure(figsize=(18,7))\n",
    "\n",
    "h_ACT0R = plt.hist(df['PeakTime0'],bins=nbins_time,range=rng_time,label=\"ACT0-R\")\n",
    "h_ACT0L = plt.hist(df['PeakTime1'],bins=nbins_time,range=rng_time,label=\"ACT0-L\")\n",
    "h_ACT1L = plt.hist(df['PeakTime2'],bins=nbins_time,range=rng_time,label=\"ACT1-R\")\n",
    "h_ACT1R = plt.hist(df['PeakTime3'],bins=nbins_time,range=rng_time,label=\"ACT1-L\")\n",
    "h_ACT3L = plt.hist(df['PeakTime4'],bins=nbins_time,range=rng_time,label=\"ACT3-R\")\n",
    "h_ACT3R = plt.hist(df['PeakTime5'],bins=nbins_time,range=rng_time,label=\"ACT3-L\")\n",
    "\n",
    "h_trig = plt.hist(df['PeakTime6'],bins=nbins_time,range=rng_time,label=\"Trigger scintillator\")\n",
    "\n",
    "h_TOF00 = plt.hist(df['PeakTime8'],bins=nbins_time,range=rng_time,label='TOF0-0')\n",
    "h_TOF01 = plt.hist(df['PeakTime9'],bins=nbins_time,range=rng_time,label='TOF0-1')\n",
    "h_TOF02 = plt.hist(df['PeakTime10'],bins=nbins_time,range=rng_time,label='TOF0-2')\n",
    "h_TOF03 = plt.hist(df['PeakTime11'],bins=nbins_time,range=rng_time,label='TOF0-3')\n",
    "\n",
    "h_TOF10 = plt.hist(df['PeakTime12'],bins=nbins_time,range=rng_time,label='TOF1-0')\n",
    "h_TOF11 = plt.hist(df['PeakTime13'],bins=nbins_time,range=rng_time,label='TOF1-1')\n",
    "h_TOF12 = plt.hist(df['PeakTime14'],bins=nbins_time,range=rng_time,label='TOF1-2')\n",
    "h_TOF13 = plt.hist(df['PeakTime15'],bins=nbins_time,range=rng_time,label='TOF1-3')\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=18)\n",
    "plt.xlabel(\"Peak time (ns)\",fontsize=18)\n",
    "\n",
    "plt.legend(loc=2,fontsize=14)\n",
    "plt.savefig(\"peak_times.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107679e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_time = [0,200]\n",
    "nbins_time = 60\n",
    "alpha_time = 0.8\n",
    "\n",
    "fig = plt.figure(figsize=(18,7))\n",
    "\n",
    "h_ACT0 = plt.hist(df['PeakTimeACT0'],bins=nbins_time,range=rng_time,label=\"ACT0 avg\",alpha=alpha_time)\n",
    "h_ACT1 = plt.hist(df['PeakTimeACT1'],bins=nbins_time,range=rng_time,label=\"ACT1 avg\",alpha=alpha_time)\n",
    "h_ACT3 = plt.hist(df[df['PeakVoltageACT3'] > 0.5]['PeakTimeACT3'],bins=nbins_time,range=rng_time,label=\"ACT3 avg (V$_{peak}$ > 0.5)\",alpha=alpha_time)\n",
    "\n",
    "h_TOF0 = plt.hist(df['PeakTimeTOF0'],bins=nbins_time,range=rng_time,label='T0 avg',alpha=alpha_time)\n",
    "h_TOF1 = plt.hist(df['PeakTimeTOF1'],bins=nbins_time,range=rng_time,label='T1 avg',alpha=alpha_time)\n",
    "\n",
    "h_trig = plt.hist(df['PeakTime6'],bins=nbins_time,range=rng_time,label=\"T2 avg\",alpha=alpha_time)\n",
    "\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=18)\n",
    "plt.xlabel(\"Peak time (ns)\",fontsize=18)\n",
    "\n",
    "plt.legend(loc=2,fontsize=18)\n",
    "plt.savefig(\"peak_times_avg.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a8dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "h2_ACT3 = ax.hist2d(df['PeakTimeACT3'],df['PeakVoltageACT3'],bins=[30,30],norm=matplotlib.colors.LogNorm())\n",
    "fig.colorbar(h2_ACT3[3],ax=ax)\n",
    "plt.xlabel(\"ACT3 avg peak time (ns)\",fontsize=12)\n",
    "plt.ylabel(\"ACT3 avg peak voltage\",fontsize=12)\n",
    "plt.savefig(\"ACT3_voltage_vs_time.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab1e1ab",
   "metadata": {},
   "source": [
    "## Hodoscope analysis\n",
    "#### These cuts allow us to see the individual peaks in the LGCharge plot below\n",
    "#### Please note these cuts are made just looking at the charge spectrum of the LG and the Hodoscope PMTs and cutting the tail, but perhaps this tail could be eliminated using cuts in the Aerogels (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7220ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "th_hd = 0.02\n",
    "cut_LG  = (df['IntCharge16'] > 0.05)\n",
    "\n",
    "cut_H0 =  df['IntCharge24'] > th_hd\n",
    "cut_H1 =  df['IntCharge25'] > th_hd\n",
    "cut_H2 =  df['IntCharge26'] > th_hd\n",
    "cut_H3 =  df['IntCharge27'] > th_hd\n",
    "cut_H4 =  df['IntCharge28'] > th_hd\n",
    "cut_H5 =  df['IntCharge29'] > th_hd\n",
    "cut_H6 =  df['IntCharge30'] > th_hd\n",
    "cut_H7 =  df['IntCharge31'] > th_hd\n",
    "cut_H8 =  df['IntCharge17'] > th_hd\n",
    "cut_H9 =  df['IntCharge18'] > th_hd\n",
    "cut_H10 = df['IntCharge19'] > th_hd\n",
    "cut_H11 = df['IntCharge20'] > th_hd\n",
    "cut_H12 = df['IntCharge21'] > th_hd\n",
    "cut_H13 = df['IntCharge22'] > th_hd\n",
    "cut_H14 = df['IntCharge23'] > th_hd\n",
    "\n",
    "LG_cal = 1. #120/3.\n",
    "#rng = [0, 500*3/120]\n",
    "rng = [0.0, 1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e8a8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6.0))\n",
    "\n",
    "plt.hist(df[cut_H14 & cut_LG]['IntCharge16']*LG_cal, bins='auto', label=\"H14\", alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H13 & cut_LG]['IntCharge16']*LG_cal, bins='auto', label=\"H13\", alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H12 & cut_LG]['IntCharge16']*LG_cal, bins='auto', label=\"H12\", alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H11 & cut_LG]['IntCharge16']*LG_cal, bins='auto', label=\"H11\", alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H10 & cut_LG]['IntCharge16']*LG_cal, bins='auto', label=\"H10\", alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H9 & cut_LG]['IntCharge16']*LG_cal,  bins='auto', label=\"H9\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H8 & cut_LG]['IntCharge16']*LG_cal,  bins='auto', label=\"H8\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H7 & cut_LG]['IntCharge16']*LG_cal,  bins='auto', label=\"H7\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H6 & cut_LG]['IntCharge16']*LG_cal,  bins='auto', label=\"H6\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H5 & cut_LG]['IntCharge16']*LG_cal,  bins='auto', label=\"H5\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H4 & cut_LG]['IntCharge16']*LG_cal,  bins='auto', label=\"H4\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H3 & cut_LG]['IntCharge16']*LG_cal,  bins='auto', label=\"H3\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H2 & cut_LG]['IntCharge16']*LG_cal,  bins='auto', label=\"H2\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H1 & cut_LG]['IntCharge16']*LG_cal,  bins='auto', label=\"H1\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H0 & cut_LG]['IntCharge16']*LG_cal,  bins='auto', label=\"H0\",  alpha=0.8, range=rng)\n",
    "  \n",
    " \n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.xlabel(\"Lead Glass (charge)\",fontsize=20)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=20)\n",
    "#plt.yscale('log')\n",
    "plt.title(\"Run {}, p = +1200 MeV/c\".format(run), fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09856349",
   "metadata": {},
   "source": [
    "## Fitting the Lead Glass Charge Peaks (HodosCope Peaks)\n",
    "#### Just a regular gaussian fit using Scipy CurveFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f9d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fc5235",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_H14 = df[cut_H14 & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H13 = df[cut_H13 & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H12 = df[cut_H12 & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H11 = df[cut_H11 & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H10 = df[cut_H10 & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H9  = df[cut_H9  & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H8  = df[cut_H8  & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H7  = df[cut_H7  & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H6  = df[cut_H6  & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H5  = df[cut_H5  & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H4  = df[cut_H4  & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H3  = df[cut_H3  & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H2  = df[cut_H2  & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H1  = df[cut_H1  & cut_LG]['IntCharge16']*LG_cal\n",
    "data_H0  = df[cut_H0  & cut_LG]['IntCharge16']*LG_cal\n",
    "\n",
    "datas = [data_H0, data_H1, data_H2, data_H3, data_H4, \n",
    "         data_H5, data_H6, data_H7, data_H8, data_H9, \n",
    "         data_H10, data_H11, data_H12, data_H13, data_H14]\n",
    "\n",
    "labels = [\"H0\", \"H1\", \"H2\", \"H3\", \"H4\", \"H5\", \"H6\", \"H7\", \"H8\", \"H9\", \"H10\", \"H11\", \"H12\", \"H13\", \"H14\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ff2c62",
   "metadata": {},
   "source": [
    "### This is not automated, you need to chage some values as you change the run, such as h, h decreasing and the text positioning since the counts decrease with the beam momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2ac07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6.0))\n",
    "h = 1400\n",
    "means = []\n",
    "\n",
    "for i,j in zip(datas, labels):    \n",
    "    data = i\n",
    "\n",
    "    hist, bin_edges = np.histogram(data, bins='auto') \n",
    "\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "    def gaussian(x, amplitude, mean, stddev):\n",
    "        return amplitude * norm.pdf(x, loc=mean, scale=stddev)\n",
    "\n",
    "    # Parámetros iniciales para el ajuste (estimaciones iniciales)\n",
    "    initial_params = [1.0, 0.0, 1.0]\n",
    "\n",
    "    # Realiza el ajuste\n",
    "    popt, _ = curve_fit(gaussian, bin_centers, hist, p0=initial_params)\n",
    "\n",
    "    # Crea una curva con los parámetros ajustados\n",
    "    fit_curve = gaussian(bin_centers, *popt)\n",
    "\n",
    "    # Grafica el histograma y la curva ajustada\n",
    "    plt.hist(data, bins='auto', alpha=0.6, label=j);\n",
    "    plt.plot(bin_centers, fit_curve, 'r-', alpha=0.6)\n",
    "    plt.text(0.9, h, 'StdDev/Mean {}: {:.2f}'.format(j, popt[2]/popt[1]),fontsize=15)\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.xlabel('Lead Glass (charge)',fontsize=20);\n",
    "    plt.ylabel('Counts/bin',fontsize=20);\n",
    "    plt.title(\"Run {}, p = +500 MeV/c\".format(run),fontsize=20);\n",
    "    \n",
    "    plt.xlim(0., 1.5)\n",
    "    \n",
    "    h -= 87\n",
    "    means.append(popt[1])\n",
    "\n",
    "    print('Valores del ajuste para {}:'.format(j))\n",
    "    print('Mean: {:.2f}'.format(popt[1]))\n",
    "    print('StdDev: {:.2f}'.format(popt[2]))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af078e0",
   "metadata": {},
   "source": [
    "# Try fitting just a determined range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6072a62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(12, 6.0))\n",
    "#h = 500\n",
    "#\n",
    "#for i,j in zip(datas, labels):    \n",
    "#    data = i\n",
    "#\n",
    "#    hist, bin_edges = np.histogram(data, bins='auto') \n",
    "#\n",
    "#    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "#\n",
    "#    def gaussian(x, amplitude, mean, stddev):\n",
    "#        return amplitude * norm.pdf(x, loc=mean, scale=stddev)\n",
    "#    \n",
    "#    # Limita los datos y el eje x hasta cierto valor máximo (por ejemplo, x = 6)\n",
    "#    max_x_value = 2.2\n",
    "#    mask = bin_centers <= max_x_value\n",
    "#    filtered_x = bin_centers[mask]\n",
    "#    filtered_hist = hist[mask]\n",
    "#\n",
    "#\n",
    "#    # Parámetros iniciales para el ajuste (estimaciones iniciales)\n",
    "#    initial_params = [1.0, 0.0, 1.0]\n",
    "#\n",
    "#    # Realiza el ajuste\n",
    "#    popt, _ = curve_fit(gaussian, filtered_x, filtered_hist, p0=initial_params)\n",
    "#\n",
    "#    # Crea una curva con los parámetros ajustados\n",
    "#    fit_curve = gaussian(filtered_x, *popt)\n",
    "#\n",
    "#    # Grafica el histograma y la curva ajustada\n",
    "#    plt.hist(data, bins='auto', alpha=0.6, label=j);\n",
    "#    plt.plot(filtered_x, fit_curve, 'r-', alpha=0.6)\n",
    "#    plt.text(2.15, h, 'StdDev {}: {:.2f}'.format(j, popt[2]),fontsize=15)\n",
    "#\n",
    "#    plt.legend()\n",
    "#    \n",
    "#    plt.xlabel('Counts/bin',fontsize=20);\n",
    "#    plt.ylabel('Lead Glass (charge)',fontsize=20);\n",
    "#    plt.title(\"Run {}, p = +800 MeV/c\".format(run),fontsize=20);\n",
    "#    \n",
    "#    plt.xlim(0.4, 3.2)\n",
    "#    \n",
    "#    h -= 27\n",
    "#\n",
    "#    #print('Valores del ajuste:')\n",
    "#    #print('Amplitude: {:.2f}'.format(popt[0]))\n",
    "#    #print('Mean: {:.2f}'.format(popt[1]))\n",
    "#    #print('StdDev: {:.2f}'.format(popt[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65703cc5",
   "metadata": {},
   "source": [
    "# 2D Plot Expected Tagged Photon Energy vs. Lead Glass Charge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb04e99",
   "metadata": {},
   "source": [
    "#### hit_energy values are the \"expected gamma energy\", computed by Josh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9879ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_energy = [0.1595155500109545, 0.16918666630815957, 0.17050944491673403, 0.18508668641801915,\n",
    "             0.1883263228952287, 0.20450156481839696, 0.21056117899451413, 0.22867222330704012,\n",
    "             0.23899202319688614, 0.25950074031219433, 0.27649806820124223, 0.30005667059694635,\n",
    "             0.32806001869009743, 0.3556345402074757, 0.40311754765565394]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883412a5",
   "metadata": {},
   "source": [
    "#### IMPORTANT: Please note that you need to change the run momentum in this next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_momentum = 500\n",
    "\n",
    "actual_means = means[::-1]\n",
    "e_gamma_expected = [run_momentum - i*1000 for i in hit_energy[::-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953db7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(actual_means, e_gamma_expected);\n",
    "\n",
    "plt.xlabel('Lead Glass Charge [Arbitrary Unit]');\n",
    "plt.ylabel('Tagged Photon Expected Momentum [MeV/c]');\n",
    "\n",
    "plt.title(\"Run {}, p = +500 MeV/c\".format(run),fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc3fc43",
   "metadata": {},
   "source": [
    "# Aerogel Charged Particle Veto\n",
    "#### Akira suggested we could use Aerogel 3 as charged particle veto ensuring only non-charged particles pass through it. Aerogels 0 & 1 can be used as veto in the opposite way. These could make us get rid of the tails that appear as beam momentum increases (see peak plots for 1200 MeV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a1c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(df['IntCharge4'], bins=40, alpha=0.7);\n",
    "plt.hist(df['IntCharge5'], bins=40, alpha=0.7);\n",
    "\n",
    "plt.yscale('log');\n",
    "\n",
    "plt.xlabel('Aerogel 3R & 3L Charge [Arbitrary Unit]');\n",
    "plt.ylabel('Counts/bins');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7194cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,7))\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.hist(df['IntCharge0'], bins=40, alpha=0.7, label='AG0R');\n",
    "ax1.hist(df['IntCharge1'], bins=40, alpha=0.7, label='AG0L');\n",
    "\n",
    "ax1.set_yscale('log');\n",
    "\n",
    "ax1.set_xlabel('Aerogel 0R & 0L Charge [Arbitrary Unit]');\n",
    "ax1.set_ylabel('Counts/bins');\n",
    "plt.legend();\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.hist(df['IntCharge2'], bins=40, alpha=0.7, label='AG1R');\n",
    "ax2.hist(df['IntCharge3'], bins=40, alpha=0.7, label='AG1L');\n",
    "\n",
    "ax2.set_yscale('log');\n",
    "\n",
    "ax2.set_xlabel('Aerogel 1R & 1L Charge [Arbitrary Unit]');\n",
    "ax2.set_ylabel('Counts/bins');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2715a4",
   "metadata": {},
   "source": [
    "#### Actual cuts for the aerogels. Many thresholds were tested and it seems like we cannot get rid of the tails using Aerogels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67acf09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag01_th = 0.0\n",
    "ag3_th  = 0.1\n",
    "\n",
    "cut_AG0R = df['IntCharge0'] > ag01_th\n",
    "cut_AG0L = df['IntCharge1'] > ag01_th\n",
    "cut_AG1R = df['IntCharge2'] > ag01_th\n",
    "cut_AG1L = df['IntCharge3'] > ag01_th\n",
    "cut_AG3R = df['IntCharge4'] < ag3_th\n",
    "cut_AG3L = df['IntCharge5'] < ag3_th\n",
    "\n",
    "cut_AG = cut_AG0R & cut_AG0L & cut_AG1R & cut_AG1L & cut_AG3R & cut_AG3L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da82a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6.0))\n",
    "\n",
    "plt.hist(df[cut_H14 & cut_LG & cut_AG]['IntCharge16']*LG_cal, bins='auto', label=\"H14\", alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H13 & cut_LG & cut_AG]['IntCharge16']*LG_cal, bins='auto', label=\"H13\", alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H12 & cut_LG & cut_AG]['IntCharge16']*LG_cal, bins='auto', label=\"H12\", alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H11 & cut_LG & cut_AG]['IntCharge16']*LG_cal, bins='auto', label=\"H11\", alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H10 & cut_LG & cut_AG]['IntCharge16']*LG_cal, bins='auto', label=\"H10\", alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H9  & cut_LG & cut_AG]['IntCharge16']*LG_cal,  bins='auto', label=\"H9\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H8  & cut_LG & cut_AG]['IntCharge16']*LG_cal,  bins='auto', label=\"H8\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H7  & cut_LG & cut_AG]['IntCharge16']*LG_cal,  bins='auto', label=\"H7\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H6  & cut_LG & cut_AG]['IntCharge16']*LG_cal,  bins='auto', label=\"H6\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H5  & cut_LG & cut_AG]['IntCharge16']*LG_cal,  bins='auto', label=\"H5\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H4  & cut_LG & cut_AG]['IntCharge16']*LG_cal,  bins='auto', label=\"H4\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H3  & cut_LG & cut_AG]['IntCharge16']*LG_cal,  bins='auto', label=\"H3\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H2  & cut_LG & cut_AG]['IntCharge16']*LG_cal,  bins='auto', label=\"H2\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H1  & cut_LG & cut_AG]['IntCharge16']*LG_cal,  bins='auto', label=\"H1\",  alpha=0.8, range=rng)\n",
    "plt.hist(df[cut_H0  & cut_LG & cut_AG]['IntCharge16']*LG_cal,  bins='auto', label=\"H0\",  alpha=0.8, range=rng)\n",
    "\n",
    " \n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.xlabel(\"Lead Glass (charge)\",fontsize=20)\n",
    "plt.ylabel(\"Counts/bin\",fontsize=20)\n",
    "#plt.yscale('log')\n",
    "plt.title(\"Run {}, p = +1200 MeV/c\".format(run), fontsize=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28cfe34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
